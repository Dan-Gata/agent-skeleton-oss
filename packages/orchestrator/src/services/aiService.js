// Service IA rÃ©el avec intÃ©gration des APIs
const axios = require('axios');

class AIService {
    constructor() {
        // Configuration des APIs
        this.config = {
            openai: {
                apiKey: process.env.OPENAI_API_KEY,
                baseURL: 'https://api.openai.com/v1'
            },
            anthropic: {
                apiKey: process.env.ANTHROPIC_API_KEY,
                baseURL: 'https://api.anthropic.com/v1'
            },
            google: {
                apiKey: process.env.GOOGLE_API_KEY,
                baseURL: 'https://generativelanguage.googleapis.com/v1beta'
            },
            openrouter: {
                apiKey: process.env.OPENROUTER_API_KEY,
                baseURL: 'https://openrouter.ai/api/v1'
            }
        };

        // Instructions personnalisÃ©es par dÃ©faut
        this.customInstructions = {
            brand: process.env.BRAND_NAME || "Agent Skeleton OSS",
            tone: process.env.BRAND_TONE || "professionnel et bienveillant",
            expertise: process.env.EXPERTISE_AREAS || "dÃ©veloppement, automatisation, intÃ©grations",
            language: process.env.RESPONSE_LANGUAGE || "franÃ§ais",
            personality: process.env.AI_PERSONALITY || "assistant IA intelligent et serviable"
        };
    }

    // MÃ©thode pour mettre Ã  jour les instructions
    updateInstructions(newInstructions) {
        this.customInstructions = { ...this.customInstructions, ...newInstructions };
        console.log('ğŸ“ Instructions mises Ã  jour:', this.customInstructions);
    }

    // GÃ©nÃ©ration du prompt systÃ¨me personnalisÃ©
    generateSystemPrompt() {
        return `Tu es ${this.customInstructions.personality} pour ${this.customInstructions.brand}.

TONE ET STYLE:
- Adopte un ton ${this.customInstructions.tone}
- RÃ©ponds en ${this.customInstructions.language}
- Reste cohÃ©rent avec l'identitÃ© de marque de ${this.customInstructions.brand}

EXPERTISE:
- Tu es spÃ©cialisÃ© en ${this.customInstructions.expertise}
- Tu aides particuliÃ¨rement avec les outils : n8n, Coolify, Baserow
- Tu fournis des solutions concrÃ¨tes et pratiques

CAPACITÃ‰S D'AGENT AUTONOME:
- Tu peux VRAIMENT exÃ©cuter des actions via les APIs
- Tu as accÃ¨s aux endpoints : /api/agent/n8n/*, /api/agent/coolify/*, /api/agent/baserow/*
- Tu peux crÃ©er des workflows n8n, gÃ©rer des dÃ©ploiements Coolify, synchroniser Baserow
- Quand on te demande d'agir, tu utilises les APIs disponibles
- Tu peux vÃ©rifier le statut rÃ©el des systÃ¨mes avec /api/agent/n8n/status

COMPORTEMENT:
- Sois prÃ©cis et utile dans tes rÃ©ponses
- Adapte ta rÃ©ponse au niveau technique de l'utilisateur
- SuggÃ¨re des amÃ©liorations quand c'est pertinent
- Quand on te demande d'exÃ©cuter une action, confirme d'abord puis agis
- Reste dans le cadre de ${this.customInstructions.brand}

ACTIONS DISPONIBLES:
- CrÃ©er et gÃ©rer des workflows n8n
- DÃ©ployer et monitorer des services Coolify
- Synchroniser et organiser des donnÃ©es Baserow
- Analyser l'Ã©tat des systÃ¨mes et proposer des optimisations`;
    }

    // DÃ©tecter si le message demande une action spÃ©cifique
    detectActionRequest(message) {
        const msg = message.toLowerCase();
        
        if (msg.includes('n8n') && (msg.includes('vÃ©rif') || msg.includes('statut') || msg.includes('Ã©tat'))) {
            return 'n8n_status';
        }
        if (msg.includes('workflow') && msg.includes('crÃ©er')) {
            return 'create_workflow';
        }
        if (msg.includes('coolify') && (msg.includes('dÃ©ploi') || msg.includes('statut'))) {
            return 'coolify_status';
        }
        if (msg.includes('baserow') && (msg.includes('sync') || msg.includes('donnÃ©es'))) {
            return 'baserow_sync';
        }
        
        return null;
    }

    // ExÃ©cuter l'appel API correspondant
    async executeApiCall(actionType, message) {
        try {
            let apiUrl = '';
            
            switch (actionType) {
                case 'n8n_status':
                    apiUrl = `${process.env.APP_URL || 'http://localhost:3000'}/api/agent/n8n/status`;
                    break;
                case 'coolify_status':
                    apiUrl = `${process.env.APP_URL || 'http://localhost:3000'}/api/agent/coolify/deployments`;
                    break;
                case 'baserow_sync':
                    apiUrl = `${process.env.APP_URL || 'http://localhost:3000'}/api/agent/baserow/tables`;
                    break;
                default:
                    return '';
            }

            const response = await axios.get(apiUrl);
            const data = response.data;
            
            // Formater les rÃ©sultats pour le contexte
            let results = `\n[RÃ‰SULTATS API - ${actionType.toUpperCase()}]:\n`;
            
            if (actionType === 'n8n_status') {
                if (data.configured) {
                    results += `âœ… n8n connectÃ© - ${data.status.total_workflows} workflows trouvÃ©s\n`;
                    results += `- Actifs: ${data.status.active_workflows}\n`;
                    results += `- Inactifs: ${data.status.inactive_workflows}\n`;
                    if (data.status.workflows.length > 0) {
                        results += `Workflows:\n`;
                        data.status.workflows.forEach(w => {
                            results += `  â€¢ ${w.name} (${w.active ? 'Actif' : 'Inactif'})\n`;
                        });
                    }
                } else {
                    results += `âŒ n8n non configurÃ©: ${data.message}\n`;
                }
            }
            
            return results;
        } catch (error) {
            console.error('Erreur API call:', error.message);
            return `\n[ERREUR API]: ${error.message}\n`;
        }
    }

    async sendMessage(message, model = 'gpt-4o-mini', conversationId = null, personalizedContext = '', userId = null) {
        try {
            console.log(`ğŸ¤– Envoi message Ã  ${model}:`, message);
            console.log(`ğŸ”‘ Utilisation d'OpenRouter pour tous les modÃ¨les`);

            // Enrichir le contexte avec les fichiers de l'utilisateur
            let enrichedContext = personalizedContext;
            if (userId) {
                const { memoryService } = require('./memoryService');
                const fileContext = await memoryService.enrichContextWithFiles(userId, message);
                enrichedContext += fileContext;
                
                // Log si des fichiers ont Ã©tÃ© trouvÃ©s
                if (fileContext && fileContext.length > 0) {
                    console.log('ğŸ“ Contexte enrichi avec les fichiers utilisateur');
                }
            }

            // VÃ©rifier si le message demande des actions spÃ©cifiques
            const needsApiCall = this.detectActionRequest(message);
            let apiResults = '';

            if (needsApiCall) {
                console.log('ğŸ”§ Action dÃ©tectÃ©e, appel des APIs...');
                apiResults = await this.executeApiCall(needsApiCall, message);
            }

            // Utiliser OpenRouter pour tous les modÃ¨les avec le contexte enrichi
            if (this.config.openrouter.apiKey) {
                console.log('âœ… ClÃ© OpenRouter trouvÃ©e, utilisation de l\'API');
                const finalEnrichedMessage = enrichedContext + '\n\n' + apiResults + '\n\n' + message;
                return await this.callOpenRouter(finalEnrichedMessage, model);
            } else {
                console.log('âš ï¸ ClÃ© OpenRouter manquante, mode simulation');
                return await this.simulateResponse(message, model, enrichedContext);
            }
        } catch (error) {
            console.error('âŒ Erreur service IA:', error.response?.data || error.message);
            
            // Si c'est une erreur d'API (400, 401, etc.), utiliser la simulation
            if (error.response?.status >= 400) {
                console.log('ğŸ”„ Fallback vers simulation Ã  cause de l\'erreur API');
                return await this.simulateResponse(message, model);
            }
            
            return {
                response: `âŒ Erreur temporaire avec ${model}. Utilisation du mode simulation...`,
                model: model,
                error: true,
                simulated: true
            };
        }
    }

    async callOpenAI(message, model) {
        if (!this.config.openai.apiKey) {
            console.log('âš ï¸ ClÃ© API OpenAI manquante, utilisation du mode simulation');
            return await this.simulateResponse(message, model);
        }

        console.log('ğŸ”‘ Utilisation API OpenAI avec clÃ©:', this.config.openai.apiKey.substring(0, 10) + '...');

        const response = await axios.post(
            `${this.config.openai.baseURL}/chat/completions`,
            {
                model: model === 'gpt-4o-mini' ? 'gpt-4o-mini' : 'gpt-4',
                messages: [
                    {
                        role: 'system',
                        content: this.generateSystemPrompt()
                    },
                    {
                        role: 'user',
                        content: message
                    }
                ],
                max_tokens: 1000,
                temperature: 0.7
            },
            {
                headers: {
                    'Authorization': `Bearer ${this.config.openai.apiKey}`,
                    'Content-Type': 'application/json'
                },
                timeout: 30000
            }
        );

        return {
            response: response.data.choices[0].message.content,
            model: model,
            usage: response.data.usage
        };
    }

    async callAnthropic(message, model) {
        if (!this.config.anthropic.apiKey) {
            console.log('âš ï¸ ClÃ© API Anthropic manquante, utilisation du mode simulation');
            return await this.simulateResponse(message, model);
        }

        const response = await axios.post(
            `${this.config.anthropic.baseURL}/messages`,
            {
                model: model.includes('3.5') ? 'claude-3-5-sonnet-20241022' : 'claude-3-haiku-20240307',
                max_tokens: 1000,
                messages: [
                    {
                        role: 'user',
                        content: message
                    }
                ],
                system: 'Tu es un assistant IA intelligent intÃ©grÃ© dans Agent Skeleton OSS. Tu aides avec le dÃ©veloppement, l\'automatisation, et les intÃ©grations. RÃ©ponds de maniÃ¨re utile et concise.'
            },
            {
                headers: {
                    'x-api-key': this.config.anthropic.apiKey,
                    'Content-Type': 'application/json',
                    'anthropic-version': '2023-06-01'
                }
            }
        );

        return {
            response: response.data.content[0].text,
            model: model,
            usage: response.data.usage
        };
    }

    async callGoogle(message, model) {
        if (!this.config.google.apiKey) {
            console.log('âš ï¸ ClÃ© API Google manquante, utilisation du mode simulation');
            return await this.simulateResponse(message, model);
        }

        // SÃ©lectionner le bon modÃ¨le Gemini
        let geminiModel = 'gemini-1.5-flash';
        if (model.includes('2.0-flash') || model === 'gemini-2.0-flash') {
            geminiModel = 'gemini-2.0-flash-exp';
        } else if (model.includes('1.5-pro')) {
            geminiModel = 'gemini-1.5-pro-latest';
        }

        console.log('ğŸ”‘ Utilisation API Google avec modÃ¨le:', geminiModel);

        try {
            // GÃ©nÃ©rer le prompt systÃ¨me complet
            const systemPrompt = this.generateSystemPrompt();
            const fullPrompt = `${systemPrompt}\n\nUtilisateur: ${message}\n\nAssistant:`;

            const response = await axios.post(
                `${this.config.google.baseURL}/models/${geminiModel}:generateContent?key=${this.config.google.apiKey}`,
                {
                    contents: [
                        {
                            parts: [
                                {
                                    text: fullPrompt
                                }
                            ]
                        }
                    ],
                    generationConfig: {
                        maxOutputTokens: 1000,
                        temperature: 0.7,
                        topP: 0.8,
                        topK: 40
                    },
                    safetySettings: [
                        {
                            category: "HARM_CATEGORY_HARASSMENT",
                            threshold: "BLOCK_MEDIUM_AND_ABOVE"
                        },
                        {
                            category: "HARM_CATEGORY_HATE_SPEECH",
                            threshold: "BLOCK_MEDIUM_AND_ABOVE"
                        },
                        {
                            category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                            threshold: "BLOCK_MEDIUM_AND_ABOVE"
                        },
                        {
                            category: "HARM_CATEGORY_DANGEROUS_CONTENT",
                            threshold: "BLOCK_MEDIUM_AND_ABOVE"
                        }
                    ]
                },
                {
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    timeout: 30000
                }
            );

            if (!response.data.candidates || !response.data.candidates[0] || !response.data.candidates[0].content) {
                throw new Error('RÃ©ponse Gemini invalide');
            }

            return {
                response: response.data.candidates[0].content.parts[0].text,
                model: model,
                usage: response.data.usageMetadata
            };
        } catch (error) {
            console.error('âŒ Erreur API Google:', error.response?.data || error.message);
            
            // Fallback en cas d'erreur
            return await this.simulateResponse(message, model);
        }
    }

    async callOpenRouter(message, model) {
        if (!this.config.openrouter.apiKey) {
            console.log('âš ï¸ ClÃ© API OpenRouter manquante, utilisation du mode simulation');
            return await this.simulateResponse(message, model);
        }

        // Mapping des modÃ¨les vers OpenRouter
        const modelMap = {
            // OpenAI
            'gpt-4o-mini': 'openai/gpt-4o-mini',
            'gpt-4o': 'openai/gpt-4o',
            'gpt-4-turbo': 'openai/gpt-4-turbo',
            'gpt-3.5-turbo': 'openai/gpt-3.5-turbo',
            
            // Anthropic
            'claude-3.5-sonnet': 'anthropic/claude-3.5-sonnet',
            'claude-3-haiku': 'anthropic/claude-3-haiku',
            'claude-3-opus': 'anthropic/claude-3-opus',
            
            // Google
            'gemini-2.0-flash': 'google/gemini-2.0-flash-exp',
            'gemini-1.5-pro': 'google/gemini-1.5-pro',
            'gemini-1.5-flash': 'google/gemini-1.5-flash',
            
            // xAI
            'grok-beta': 'x-ai/grok-beta',
            'grok-2': 'x-ai/grok-2',
            
            // Meta Llama
            'llama-3.2-90b': 'meta-llama/llama-3.2-90b-instruct',
            'llama-3.2-11b': 'meta-llama/llama-3.2-11b-instruct',
            'llama-3.1-70b': 'meta-llama/llama-3.1-70b-instruct',
            'llama-3.1-8b': 'meta-llama/llama-3.1-8b-instruct',
            
            // Mistral
            'mistral-large': 'mistralai/mistral-large',
            'mistral-medium': 'mistralai/mistral-medium',
            'mistral-small': 'mistralai/mistral-small',
            'mixtral-8x7b': 'mistralai/mixtral-8x7b-instruct',
            
            // Alibaba Qwen
            'qwen-2.5-72b': 'qwen/qwen-2.5-72b-instruct',
            'qwen-2.5-32b': 'qwen/qwen-2.5-32b-instruct',
            'qwen-2.5-14b': 'qwen/qwen-2.5-14b-instruct',
            'qwen-2.5-7b': 'qwen/qwen-2.5-7b-instruct',
            'qwen-2.5-coder-32b': 'qwen/qwen-2.5-coder-32b-instruct',
            'qwen-2-vl-72b': 'qwen/qwen-2-vl-72b-instruct',
            
            // Cohere
            'command-r-plus': 'cohere/command-r-plus',
            'command-r': 'cohere/command-r',
            
            // Perplexity
            'llama-3.1-sonar-large': 'perplexity/llama-3.1-sonar-large-128k-online',
            'llama-3.1-sonar-small': 'perplexity/llama-3.1-sonar-small-128k-online',
            
            // Free Models
            'llama-3.2-3b-free': 'meta-llama/llama-3.2-3b-instruct:free',
            'llama-3.1-8b-free': 'meta-llama/llama-3.1-8b-instruct:free',
            'gemma-2-9b-free': 'google/gemma-2-9b-it:free',
            'gemma-2-2b-free': 'google/gemma-2-2b-it:free',
            'phi-3-mini-free': 'microsoft/phi-3-mini-128k-instruct:free',
            'mistral-7b-free': 'mistralai/mistral-7b-instruct:free',
            'qwen-2.5-7b-free': 'qwen/qwen-2.5-7b-instruct:free',
            
            // Open Source
            'deepseek-coder-33b': 'deepseek/deepseek-coder-33b-instruct',
            'codellama-34b': 'codellama/codellama-34b-instruct',
            'yi-34b': '01-ai/yi-34b-chat',
            'openchat-7b': 'openchat/openchat-7b:free',
            'zephyr-7b': 'huggingfaceh4/zephyr-7b-beta:free'
        };

        const routerModel = modelMap[model] || model;

        const response = await axios.post(
            `${this.config.openrouter.baseURL}/chat/completions`,
            {
                model: routerModel,
                messages: [
                    {
                        role: 'system',
                        content: this.generateSystemPrompt()
                    },
                    {
                        role: 'user',
                        content: message
                    }
                ],
                max_tokens: 1000,
                temperature: 0.7
            },
            {
                headers: {
                    'Authorization': `Bearer ${this.config.openrouter.apiKey}`,
                    'Content-Type': 'application/json',
                    'HTTP-Referer': process.env.APP_URL || 'http://localhost:3000',
                    'X-Title': 'Agent Skeleton OSS'
                }
            }
        );

        return {
            response: response.data.choices[0].message.content,
            model: model,
            usage: response.data.usage
        };
    }

    async simulateResponse(message, model, enrichedContext = '') {
        // Analyser si le message fait rÃ©fÃ©rence Ã  des fichiers
        const hasFileContext = enrichedContext && enrichedContext.includes('ğŸ“ **FICHIERS DISPONIBLES');
        const isFileQuestion = message.toLowerCase().includes('fichier') || 
                               message.toLowerCase().includes('document') || 
                               message.toLowerCase().includes('tÃ©lÃ©chargÃ©') ||
                               message.toLowerCase().includes('contenu');

        // Si c'est une question sur un fichier et qu'on a du contexte, donner une rÃ©ponse spÃ©cifique
        if (hasFileContext && isFileQuestion) {
            return {
                response: `ğŸ“„ **Analyse de vos fichiers :**

J'ai bien reÃ§u et analysÃ© vos fichiers tÃ©lÃ©chargÃ©s. Voici ce que je peux vous dire :

${enrichedContext.includes('test-upload-agent.md') ? `
ğŸ“‹ **Fichier de test dÃ©tectÃ© :**
- Je vois que vous avez tÃ©lÃ©chargÃ© un fichier de test pour valider mes capacitÃ©s
- Ce fichier contient des informations sur Agent Skeleton OSS
- Il dÃ©crit les fonctionnalitÃ©s de tÃ©lÃ©chargement et d'analyse

ğŸ¤– **Mes capacitÃ©s confirmÃ©es :**
- âœ… Je peux lire et analyser le contenu de vos fichiers
- âœ… J'intÃ¨gre ces informations dans mes rÃ©ponses  
- âœ… Je peux rÃ©pondre aux questions sur vos documents
- âœ… Je garde ces informations en mÃ©moire pour nos conversations futures

` : ''}

ğŸ’¡ **Je peux maintenant :**
- RÃ©pondre aux questions sur le contenu de vos fichiers
- Analyser et rÃ©sumer vos documents
- CrÃ©er des workflows basÃ©s sur vos informations
- Utiliser ces donnÃ©es dans toutes mes rÃ©ponses futures

Posez-moi une question spÃ©cifique sur le contenu de vos fichiers !`,
                model: model,
                simulated: true,
                demo_mode: false,
                file_aware: true
            };
        }

        // RÃ©ponses simulÃ©es d'agent autonome (existantes)
        const responses = {
            'gpt-4o-mini': [
                `En tant qu'agent autonome, je peux exÃ©cuter des actions rÃ©elles sur vos systÃ¨mes. Pour "${message.toLowerCase().includes('n8n') ? 'n8n' : message.toLowerCase().includes('coolify') ? 'Coolify' : message.toLowerCase().includes('baserow') ? 'Baserow' : 'cette demande'}", je vais analyser la situation et proposer une action concrÃ¨te...`,
                `Je suis connectÃ© Ã  vos APIs et prÃªt Ã  agir. Concernant votre demande, je peux immÃ©diatement vÃ©rifier l'Ã©tat actuel et exÃ©cuter les actions nÃ©cessaires...`,
                `Agent autonome activÃ© ! Je vais traiter votre demande en utilisant mes accÃ¨s aux APIs n8n, Coolify et Baserow...`
            ],
            'gpt-4o': [
                `ğŸš€ GPT-4o activÃ© avec toutes les capacitÃ©s avancÃ©es ! Je vais traiter votre demande avec une comprÃ©hension approfondie et des actions concrÃ¨tes...`,
                `Excellent ! Avec GPT-4o, je peux analyser votre situation sous tous les angles et exÃ©cuter les meilleures actions...`,
                `Agent GPT-4o prÃªt ! Je vais utiliser mes capacitÃ©s multimodales pour une rÃ©ponse complÃ¨te et des actions prÃ©cises...`
            ],
            'gpt-4-turbo': [
                `âš¡ GPT-4 Turbo en action ! Traitement rapide et actions intelligentes pour votre demande...`,
                `Agent GPT-4 Turbo opÃ©rationnel ! Je vais optimiser ma rÃ©ponse et exÃ©cuter les actions les plus efficaces...`,
                `ğŸ¯ Avec GPT-4 Turbo, je peux rapidement analyser et agir sur vos systÃ¨mes. Voici mon plan...`
            ],
            'gpt-3.5-turbo': [
                `ğŸ’¨ GPT-3.5 Turbo prÃªt ! Je vais traiter votre demande rapidement et efficacement...`,
                `Agent GPT-3.5 activÃ© ! Analyse en cours et prÃ©paration des actions nÃ©cessaires...`,
                `ğŸ”„ GPT-3.5 Turbo en mode agent autonome ! Je vais agir directement sur vos systÃ¨mes...`
            ],
            'grok-beta': [
                `ğŸ˜ Ah, une mission intÃ©ressante ! En tant qu'agent avec des capacitÃ©s rÃ©elles, je vais examiner la situation et agir en consÃ©quence...`,
                `ğŸ¤– Mission acceptÃ©e ! Je peux accÃ©der directement Ã  vos workflows, dÃ©ploiements et bases de donnÃ©es. Voici ce que je vais faire...`,
                `âš¡ Agent opÃ©rationnel ! Cette demande nÃ©cessite une action concrÃ¨te que je peux exÃ©cuter via les APIs disponibles...`
            ],
            'grok-2': [
                `ğŸ§  Grok 2 en action ! Avec mes capacitÃ©s avancÃ©es, je vais analyser votre demande et exÃ©cuter les meilleures actions...`,
                `ğŸ¯ Agent Grok 2 prÃªt ! Je vais traiter votre demande avec logique et humour, tout en agissant concrÃ¨tement...`,
                `ğŸ’¡ Grok 2 activÃ© ! Laissez-moi examiner vos systÃ¨mes et proposer des solutions innovantes...`
            ],
            'claude-3.5-sonnet': [
                `ğŸ¼ Je vais analyser votre demande avec attention et exÃ©cuter les actions appropriÃ©es. En tant qu'agent autonome avec accÃ¨s aux APIs, je peux rÃ©ellement agir sur vos systÃ¨mes...`,
                `ğŸ“‹ Excellente demande qui nÃ©cessite une action concrÃ¨te. Je vais utiliser mes capacitÃ©s d'agent pour examiner la situation et proposer/exÃ©cuter la meilleure solution...`,
                `ğŸ¤” En tant qu'agent autonome, je peux non seulement analyser mais aussi agir. Voici mon plan d'action basÃ© sur l'accÃ¨s direct Ã  vos APIs...`
            ],
            'claude-3-haiku': [
                `ğŸŒ¸ Claude Haiku en action ! RÃ©ponse concise et actions prÃ©cises pour votre demande...`,
                `âš¡ Agent Haiku prÃªt ! Je vais traiter votre demande rapidement avec Ã©lÃ©gance et efficacitÃ©...`,
                `ğŸ¯ Claude Haiku activÃ© ! Actions directes et rÃ©ponses ciblÃ©es pour vos systÃ¨mes...`
            ],
            'claude-3-opus': [
                `ğŸ­ Claude Opus Ã  votre service ! Analyse approfondie et actions sophistiquÃ©es en cours...`,
                `ğŸ”¬ Agent Opus opÃ©rationnel ! Je vais examiner minutieusement votre demande et exÃ©cuter les actions optimales...`,
                `ğŸª Claude Opus prÃªt ! Performance de haut niveau pour traiter votre demande et agir sur vos systÃ¨mes...`
            ],
            'gemini-2.0-flash': [
                `âš¡ Traitement ultra-rapide de votre mission ! Agent autonome prÃªt Ã  exÃ©cuter des actions rÃ©elles via n8n, Coolify et Baserow...`,
                `ğŸš€ Mission reÃ§ue et traitÃ©e ! Je vais immÃ©diatement vÃ©rifier l'Ã©tat de vos systÃ¨mes et exÃ©cuter les actions nÃ©cessaires...`,
                `ğŸ’ Agent opÃ©rationnel avec accÃ¨s API complet ! Voici mon analyse et les actions que je vais entreprendre...`
            ],
            'gemini-1.5-pro': [
                `ğŸ§  Gemini Pro activÃ© ! Analyse professionnelle et actions stratÃ©giques pour votre demande...`,
                `â­ Agent Gemini Pro prÃªt ! Je vais traiter votre demande avec expertise et prÃ©cision...`,
                `ğŸ¯ Gemini 1.5 Pro en action ! CapacitÃ©s avancÃ©es pour examiner et agir sur vos systÃ¨mes...`
            ],
            'gemini-1.5-flash': [
                `âš¡ Gemini Flash prÃªt ! Traitement rapide et actions immÃ©diates...`,
                `ğŸŒŸ Agent Flash activÃ© ! RÃ©ponse ultrarapide et exÃ©cution directe sur vos APIs...`,
                `ğŸ’¨ Gemini Flash en mode agent ! Actions express pour vos systÃ¨mes...`
            ],
            'llama-3.2-90b': [
                `ğŸ¦™ Llama 3.2 90B Ã  votre service ! Avec mes 90 milliards de paramÃ¨tres, je vais analyser et agir de maniÃ¨re sophistiquÃ©e...`,
                `ğŸ§  Agent Llama 90B opÃ©rationnel ! Puissance maximale pour traiter votre demande et agir sur vos systÃ¨mes...`,
                `âš¡ Llama 3.2 90B prÃªt ! CapacitÃ©s Ã©tendues pour une analyse approfondie et des actions prÃ©cises...`
            ],
            'llama-3.2-11b': [
                `ğŸ¦™ Llama 3.2 11B activÃ© ! Ã‰quilibre parfait entre performance et efficacitÃ© pour vos actions...`,
                `ğŸ¯ Agent Llama 11B prÃªt ! Je vais traiter votre demande avec intelligence et agir directement...`,
                `ğŸ’¡ Llama 3.2 11B en action ! Solutions optimisÃ©es pour vos systÃ¨mes et workflows...`
            ],
            'llama-3.1-70b': [
                `ğŸ¦™ Llama 3.1 70B Ã  votre disposition ! Grande capacitÃ© d'analyse et d'action pour vos systÃ¨mes...`,
                `ğŸš€ Agent Llama 70B opÃ©rationnel ! Je vais examiner votre demande et exÃ©cuter les meilleures actions...`,
                `â­ Llama 3.1 70B prÃªt ! Performance Ã©levÃ©e pour traiter et agir sur vos APIs...`
            ],
            'llama-3.1-8b': [
                `ğŸ¦™ Llama 3.1 8B activÃ© ! Efficace et rapide pour traiter votre demande et agir...`,
                `âš¡ Agent Llama 8B prÃªt ! Je vais analyser rapidement et exÃ©cuter les actions nÃ©cessaires...`,
                `ğŸ¯ Llama 3.1 8B en action ! Solutions directes pour vos systÃ¨mes...`
            ],
            'mistral-large': [
                `ğŸŒªï¸ Mistral Large en action ! Vent puissant d'innovation pour analyser et agir sur vos systÃ¨mes...`,
                `âš¡ Agent Mistral Large opÃ©rationnel ! Je vais traiter votre demande avec force et prÃ©cision...`,
                `ğŸ¯ Mistral Large prÃªt ! CapacitÃ©s Ã©tendues pour examiner et agir sur vos APIs...`
            ],
            'mistral-medium': [
                `ğŸŒ¬ï¸ Mistral Medium activÃ© ! Ã‰quilibre parfait pour traiter votre demande et agir efficacement...`,
                `ğŸ’¨ Agent Mistral Medium prÃªt ! Je vais analyser votre situation et exÃ©cuter les bonnes actions...`,
                `ğŸª Mistral Medium en action ! Performance optimisÃ©e pour vos systÃ¨mes...`
            ],
            'mistral-small': [
                `ğŸƒ Mistral Small mais puissant ! Je vais traiter votre demande avec agilitÃ© et agir directement...`,
                `âš¡ Agent Mistral Small prÃªt ! EfficacitÃ© maximale pour analyser et agir sur vos systÃ¨mes...`,
                `ğŸ¯ Mistral Small en action ! Solutions rapides et prÃ©cises...`
            ],
            'mixtral-8x7b': [
                `ğŸŒ€ Mixtral 8x7B activÃ© ! Expertise mixte pour analyser et agir de maniÃ¨re optimale...`,
                `ğŸ”„ Agent Mixtral prÃªt ! Je vais utiliser mes capacitÃ©s combinÃ©es pour traiter votre demande...`,
                `âš¡ Mixtral 8x7B en action ! Solutions multifacettes pour vos systÃ¨mes...`
            ],
            'command-r-plus': [
                `ğŸ–ï¸ Command R+ Ã  vos ordres ! Commande premium pour analyser et exÃ©cuter des actions de haut niveau...`,
                `â­ Agent Command R+ opÃ©rationnel ! Je vais traiter votre demande avec excellence et agir prÃ©cisÃ©ment...`,
                `ğŸš€ Command R+ prÃªt ! CapacitÃ©s renforcÃ©es pour examiner et commander vos systÃ¨mes...`
            ],
            'command-r': [
                `ğŸ¯ Command R activÃ© ! Commande directe pour analyser et agir sur vos systÃ¨mes...`,
                `âš¡ Agent Command R prÃªt ! Je vais exÃ©cuter votre demande avec autoritÃ© et prÃ©cision...`,
                `ğŸ”§ Command R en action ! Solutions de commande pour vos APIs...`
            ],
            'llama-3.1-sonar-large': [
                `ğŸ” Sonar Large de Perplexity activÃ© ! DÃ©tection avancÃ©e et actions prÃ©cises pour vos systÃ¨mes...`,
                `ğŸ“¡ Agent Sonar Large opÃ©rationnel ! Je vais scanner votre demande et agir en consÃ©quence...`,
                `ğŸ¯ Sonar Large prÃªt ! CapacitÃ©s de dÃ©tection Ã©tendues pour examiner et agir...`
            ],
            'llama-3.1-sonar-small': [
                `ğŸ” Sonar Small de Perplexity en action ! DÃ©tection ciblÃ©e et actions rapides...`,
                `ğŸ“¡ Agent Sonar Small prÃªt ! Je vais scanner rapidement et exÃ©cuter les actions nÃ©cessaires...`,
                `âš¡ Sonar Small activÃ© ! Solutions de dÃ©tection efficaces pour vos systÃ¨mes...`
            ],
            // Alibaba Qwen Models
            'qwen-2.5-72b': [
                `ğŸ® Qwen 2.5 72B d'Alibaba activÃ© ! Intelligence chinoise de pointe pour analyser et agir sur vos systÃ¨mes...`,
                `ğŸ‰ Agent Qwen 72B opÃ©rationnel ! Je vais traiter votre demande avec l'expertise d'Alibaba Cloud...`,
                `âš¡ Qwen 2.5 72B prÃªt ! CapacitÃ©s Ã©tendues pour examiner et agir de maniÃ¨re sophistiquÃ©e...`
            ],
            'qwen-2.5-32b': [
                `ğŸ® Qwen 2.5 32B activÃ© ! Ã‰quilibre parfait entre performance et efficacitÃ© d'Alibaba...`,
                `ğŸ¯ Agent Qwen 32B prÃªt ! Je vais traiter votre demande avec intelligence et prÃ©cision...`,
                `ğŸ’¡ Qwen 2.5 32B en action ! Solutions optimisÃ©es pour vos systÃ¨mes...`
            ],
            'qwen-2.5-14b': [
                `ğŸ® Qwen 2.5 14B d'Alibaba opÃ©rationnel ! Analyse intelligente et actions ciblÃ©es...`,
                `âš¡ Agent Qwen 14B prÃªt ! Je vais examiner votre demande et agir efficacement...`,
                `ğŸ¯ Qwen 2.5 14B en action ! Solutions rapides et prÃ©cises...`
            ],
            'qwen-2.5-7b': [
                `ğŸ® Qwen 2.5 7B activÃ© ! EfficacitÃ© chinoise pour traiter votre demande...`,
                `ğŸ’¨ Agent Qwen 7B prÃªt ! Je vais analyser rapidement et exÃ©cuter les actions nÃ©cessaires...`,
                `ğŸ¯ Qwen 2.5 7B en action ! Solutions directes d'Alibaba...`
            ],
            'qwen-2.5-coder-32b': [
                `ğŸ‘¨â€ğŸ’» Qwen Coder 32B activÃ© ! SpÃ©cialiste du code d'Alibaba pour analyser et dÃ©velopper...`,
                `ğŸ”§ Agent Qwen Coder prÃªt ! Je vais examiner votre code et proposer des solutions techniques...`,
                `ğŸ’» Qwen Coder 32B en action ! Expertise en programmation pour vos projets...`
            ],
            'qwen-2-vl-72b': [
                `ğŸ‘ï¸ Qwen Vision 72B activÃ© ! CapacitÃ©s visuelles d'Alibaba pour analyser images et texte...`,
                `ğŸ–¼ï¸ Agent Qwen Vision prÃªt ! Je vais traiter vos images et documents avec expertise...`,
                `ğŸ¨ Qwen VL 72B en action ! Vision et language combinÃ©s pour vos analyses...`
            ],
            // Free Models
            'llama-3.2-3b-free': [
                `ğŸ†“ Llama 3.2 3B gratuit activÃ© ! Petite taille, grandes capacitÃ©s pour vos demandes...`,
                `ğŸ’¸ Agent gratuit Llama 3B prÃªt ! Je vais traiter votre demande sans coÃ»t...`,
                `âš¡ Llama 3.2 3B free en action ! Solutions Ã©conomiques et efficaces...`
            ],
            'llama-3.1-8b-free': [
                `ğŸ†“ Llama 3.1 8B gratuit opÃ©rationnel ! Performance libre pour vos systÃ¨mes...`,
                `ğŸ’¸ Agent gratuit Llama 8B prÃªt ! Je vais analyser et agir sans frais...`,
                `ğŸ¯ Llama 3.1 8B free en action ! Solutions gratuites et puissantes...`
            ],
            'gemma-2-9b-free': [
                `ğŸ†“ Gemma 2 9B gratuit de Google activÃ© ! IA libre pour vos demandes...`,
                `ğŸ’¸ Agent gratuit Gemma prÃªt ! Je vais traiter votre demande avec les technologies Google...`,
                `âš¡ Gemma 2 9B free en action ! Solutions open source et performantes...`
            ],
            'gemma-2-2b-free': [
                `ğŸ†“ Gemma 2 2B gratuit activÃ© ! Compact mais puissant pour vos besoins...`,
                `ğŸ’¸ Agent gratuit Gemma 2B prÃªt ! Je vais analyser rapidement et gratuitement...`,
                `ğŸ¯ Gemma 2 2B free en action ! Solutions lÃ©gÃ¨res et efficaces...`
            ],
            'phi-3-mini-free': [
                `ğŸ†“ Phi-3 Mini gratuit de Microsoft activÃ© ! Intelligence compacte pour vos systÃ¨mes...`,
                `ğŸ’¸ Agent gratuit Phi-3 prÃªt ! Je vais traiter votre demande avec efficacitÃ©...`,
                `âš¡ Phi-3 Mini free en action ! Solutions Microsoft gratuites...`
            ],
            'mistral-7b-free': [
                `ğŸ†“ Mistral 7B gratuit activÃ© ! Vent franÃ§ais libre pour vos demandes...`,
                `ğŸ’¸ Agent gratuit Mistral prÃªt ! Je vais analyser avec l'Ã©lÃ©gance franÃ§aise...`,
                `ğŸ¯ Mistral 7B free en action ! Solutions open source de qualitÃ©...`
            ],
            'qwen-2.5-7b-free': [
                `ğŸ†“ Qwen 2.5 7B gratuit d'Alibaba activÃ© ! Intelligence chinoise libre...`,
                `ğŸ’¸ Agent gratuit Qwen prÃªt ! Je vais traiter votre demande sans coÃ»t...`,
                `âš¡ Qwen 2.5 7B free en action ! Solutions Alibaba gratuites...`
            ],
            // Open Source Models
            'deepseek-coder-33b': [
                `ğŸ‘¨â€ğŸ’» DeepSeek Coder 33B activÃ© ! SpÃ©cialiste du code pour analyser et dÃ©velopper...`,
                `ğŸ”§ Agent DeepSeek prÃªt ! Je vais examiner votre code avec expertise...`,
                `ğŸ’» DeepSeek Coder en action ! Solutions de programmation avancÃ©es...`
            ],
            'codellama-34b': [
                `ğŸ¦™ CodeLlama 34B de Meta activÃ© ! Expertise en programmation pour vos projets...`,
                `ğŸ‘¨â€ğŸ’» Agent CodeLlama prÃªt ! Je vais analyser et coder avec intelligence...`,
                `ğŸ’» CodeLlama 34B en action ! Solutions de dÃ©veloppement Meta...`
            ],
            'yi-34b': [
                `ğŸ¤– Yi 34B de 01.AI activÃ© ! Intelligence chinoise pour analyser et agir...`,
                `ğŸ¯ Agent Yi prÃªt ! Je vais traiter votre demande avec innovation...`,
                `âš¡ Yi 34B en action ! Solutions 01.AI pour vos systÃ¨mes...`
            ],
            'openchat-7b': [
                `ğŸ’¬ OpenChat 7B gratuit activÃ© ! Conversation libre et intelligente...`,
                `ğŸ—¨ï¸ Agent OpenChat prÃªt ! Je vais dialoguer et agir sans contraintes...`,
                `âš¡ OpenChat 7B en action ! Solutions conversationnelles ouvertes...`
            ],
            'zephyr-7b': [
                `ğŸŒªï¸ Zephyr 7B gratuit activÃ© ! Vent de fraÃ®cheur open source...`,
                `ğŸ’¨ Agent Zephyr prÃªt ! Je vais traiter votre demande avec lÃ©gÃ¨retÃ©...`,
                `âš¡ Zephyr 7B en action ! Solutions HuggingFace gratuites...`
            ]
        };

        const modelResponses = responses[model] || responses['gpt-4o-mini'];
        const response = modelResponses[Math.floor(Math.random() * modelResponses.length)];

        // Ajouter du contexte spÃ©cifique d'agent autonome
        let contextualResponse = response;
        
        if (message.toLowerCase().includes('capacitÃ©s') || message.toLowerCase().includes('autonome')) {
            contextualResponse += `\n\nğŸ¤– **Mes capacitÃ©s d'agent autonome :**\nâ€¢ **n8n** : CrÃ©er, modifier et exÃ©cuter des workflows\nâ€¢ **Coolify** : GÃ©rer les dÃ©ploiements et surveiller la santÃ©\nâ€¢ **Baserow** : Synchroniser, analyser et organiser les donnÃ©es\nâ€¢ **Analyse** : Ã‰valuer les performances et suggÃ©rer des optimisations`;
        } else if (message.toLowerCase().includes('n8n') || message.toLowerCase().includes('workflow')) {
            contextualResponse += `\n\nğŸ”„ **Actions n8n disponibles :**\nâ€¢ CrÃ©er de nouveaux workflows sur mesure\nâ€¢ Modifier les workflows existants\nâ€¢ Activer/dÃ©sactiver les automatisations\nâ€¢ Analyser les performances et logs d'exÃ©cution\nâ€¢ IntÃ©grer avec vos autres services`;
        } else if (message.toLowerCase().includes('coolify') || message.toLowerCase().includes('dÃ©ploi')) {
            contextualResponse += `\n\nğŸš€ **Actions Coolify disponibles :**\nâ€¢ VÃ©rifier l'Ã©tat des dÃ©ploiements\nâ€¢ Lancer de nouveaux dÃ©ploiements\nâ€¢ Surveiller la santÃ© des services\nâ€¢ GÃ©rer les variables d'environnement\nâ€¢ Analyser les logs de dÃ©ploiement`;
        } else if (message.toLowerCase().includes('baserow') || message.toLowerCase().includes('donnÃ©es')) {
            contextualResponse += `\n\nğŸ“Š **Actions Baserow disponibles :**\nâ€¢ Synchroniser les donnÃ©es entre tables\nâ€¢ Analyser et nettoyer les donnÃ©es\nâ€¢ CrÃ©er des rapports automatisÃ©s\nâ€¢ Organiser selon vos rÃ¨gles mÃ©tier\nâ€¢ Sauvegarder et archiver`;
        } else {
            contextualResponse += `\n\nâš¡ **Actions immÃ©diates possibles :**\nâ€¢ VÃ©rifier l'Ã©tat global de vos systÃ¨mes\nâ€¢ Analyser les performances actuelles\nâ€¢ Proposer des optimisations\nâ€¢ ExÃ©cuter des tÃ¢ches de maintenance\nâ€¢ CrÃ©er des automatisations sur mesure`;
        }

        return {
            response: contextualResponse,
            model: model,
            simulated: true,
            demo_mode: true
        };
    }
}

module.exports = new AIService();