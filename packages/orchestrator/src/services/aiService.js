// Service IA r√©el avec int√©gration des APIs
const axios = require('axios');

class AIService {
    constructor() {
        // Configuration des APIs
        this.config = {
            openai: {
                apiKey: process.env.OPENAI_API_KEY,
                baseURL: 'https://api.openai.com/v1'
            },
            anthropic: {
                apiKey: process.env.ANTHROPIC_API_KEY,
                baseURL: 'https://api.anthropic.com/v1'
            },
            google: {
                apiKey: process.env.GOOGLE_API_KEY,
                baseURL: 'https://generativelanguage.googleapis.com/v1beta'
            },
            openrouter: {
                apiKey: process.env.OPENROUTER_API_KEY,
                baseURL: 'https://openrouter.ai/api/v1'
            }
        };

        // Instructions personnalis√©es par d√©faut
        this.customInstructions = {
            brand: process.env.BRAND_NAME || "Agent Skeleton OSS",
            tone: process.env.BRAND_TONE || "professionnel et bienveillant",
            expertise: process.env.EXPERTISE_AREAS || "d√©veloppement, automatisation, int√©grations",
            language: process.env.RESPONSE_LANGUAGE || "fran√ßais",
            personality: process.env.AI_PERSONALITY || "assistant IA intelligent et serviable"
        };
    }

    // M√©thode pour mettre √† jour les instructions
    updateInstructions(newInstructions) {
        this.customInstructions = { ...this.customInstructions, ...newInstructions };
        console.log('üìù Instructions mises √† jour:', this.customInstructions);
    }

    // G√©n√©ration du prompt syst√®me personnalis√©
    generateSystemPrompt() {
        return `Tu es ${this.customInstructions.personality} pour ${this.customInstructions.brand}.

TONE ET STYLE:
- Adopte un ton ${this.customInstructions.tone}
- R√©ponds en ${this.customInstructions.language}
- Reste coh√©rent avec l'identit√© de marque de ${this.customInstructions.brand}

EXPERTISE:
- Tu es sp√©cialis√© en ${this.customInstructions.expertise}
- Tu aides particuli√®rement avec les outils : n8n, Coolify, Baserow
- Tu fournis des solutions concr√®tes et pratiques

CAPACIT√âS D'AGENT AUTONOME:
- Tu peux VRAIMENT ex√©cuter des actions via les APIs
- Tu as acc√®s aux endpoints : /api/agent/n8n/*, /api/agent/coolify/*, /api/agent/baserow/*
- Tu peux cr√©er des workflows n8n, g√©rer des d√©ploiements Coolify, synchroniser Baserow
- Quand on te demande d'agir, tu utilises les APIs disponibles

COMPORTEMENT:
- Sois pr√©cis et utile dans tes r√©ponses
- Adapte ta r√©ponse au niveau technique de l'utilisateur
- Sugg√®re des am√©liorations quand c'est pertinent
- Quand on te demande d'ex√©cuter une action, confirme d'abord puis agis
- Reste dans le cadre de ${this.customInstructions.brand}

ACTIONS DISPONIBLES:
- Cr√©er et g√©rer des workflows n8n
- D√©ployer et monitorer des services Coolify
- Synchroniser et organiser des donn√©es Baserow
- Analyser l'√©tat des syst√®mes et proposer des optimisations`;
    }

    async sendMessage(message, model = 'gpt-4o-mini', conversationId = null) {
        try {
            console.log(`ü§ñ Envoi message √† ${model}:`, message);
            console.log(`üîë Utilisation d'OpenRouter pour tous les mod√®les`);

            // Utiliser OpenRouter pour tous les mod√®les
            if (this.config.openrouter.apiKey) {
                console.log('‚úÖ Cl√© OpenRouter trouv√©e, utilisation de l\'API');
                return await this.callOpenRouter(message, model);
            } else {
                console.log('‚ö†Ô∏è Cl√© OpenRouter manquante, mode simulation');
                return await this.simulateResponse(message, model);
            }
        } catch (error) {
            console.error('‚ùå Erreur service IA:', error.response?.data || error.message);
            
            // Si c'est une erreur d'API (400, 401, etc.), utiliser la simulation
            if (error.response?.status >= 400) {
                console.log('üîÑ Fallback vers simulation √† cause de l\'erreur API');
                return await this.simulateResponse(message, model);
            }
            
            return {
                response: `‚ùå Erreur temporaire avec ${model}. Utilisation du mode simulation...`,
                model: model,
                error: true,
                simulated: true
            };
        }
    }

    async callOpenAI(message, model) {
        if (!this.config.openai.apiKey) {
            console.log('‚ö†Ô∏è Cl√© API OpenAI manquante, utilisation du mode simulation');
            return await this.simulateResponse(message, model);
        }

        console.log('üîë Utilisation API OpenAI avec cl√©:', this.config.openai.apiKey.substring(0, 10) + '...');

        const response = await axios.post(
            `${this.config.openai.baseURL}/chat/completions`,
            {
                model: model === 'gpt-4o-mini' ? 'gpt-4o-mini' : 'gpt-4',
                messages: [
                    {
                        role: 'system',
                        content: this.generateSystemPrompt()
                    },
                    {
                        role: 'user',
                        content: message
                    }
                ],
                max_tokens: 1000,
                temperature: 0.7
            },
            {
                headers: {
                    'Authorization': `Bearer ${this.config.openai.apiKey}`,
                    'Content-Type': 'application/json'
                },
                timeout: 30000
            }
        );

        return {
            response: response.data.choices[0].message.content,
            model: model,
            usage: response.data.usage
        };
    }

    async callAnthropic(message, model) {
        if (!this.config.anthropic.apiKey) {
            console.log('‚ö†Ô∏è Cl√© API Anthropic manquante, utilisation du mode simulation');
            return await this.simulateResponse(message, model);
        }

        const response = await axios.post(
            `${this.config.anthropic.baseURL}/messages`,
            {
                model: model.includes('3.5') ? 'claude-3-5-sonnet-20241022' : 'claude-3-haiku-20240307',
                max_tokens: 1000,
                messages: [
                    {
                        role: 'user',
                        content: message
                    }
                ],
                system: 'Tu es un assistant IA intelligent int√©gr√© dans Agent Skeleton OSS. Tu aides avec le d√©veloppement, l\'automatisation, et les int√©grations. R√©ponds de mani√®re utile et concise.'
            },
            {
                headers: {
                    'x-api-key': this.config.anthropic.apiKey,
                    'Content-Type': 'application/json',
                    'anthropic-version': '2023-06-01'
                }
            }
        );

        return {
            response: response.data.content[0].text,
            model: model,
            usage: response.data.usage
        };
    }

    async callGoogle(message, model) {
        if (!this.config.google.apiKey) {
            console.log('‚ö†Ô∏è Cl√© API Google manquante, utilisation du mode simulation');
            return await this.simulateResponse(message, model);
        }

        // S√©lectionner le bon mod√®le Gemini
        let geminiModel = 'gemini-1.5-flash';
        if (model.includes('2.0-flash') || model === 'gemini-2.0-flash') {
            geminiModel = 'gemini-2.0-flash-exp';
        } else if (model.includes('1.5-pro')) {
            geminiModel = 'gemini-1.5-pro-latest';
        }

        console.log('üîë Utilisation API Google avec mod√®le:', geminiModel);

        try {
            // G√©n√©rer le prompt syst√®me complet
            const systemPrompt = this.generateSystemPrompt();
            const fullPrompt = `${systemPrompt}\n\nUtilisateur: ${message}\n\nAssistant:`;

            const response = await axios.post(
                `${this.config.google.baseURL}/models/${geminiModel}:generateContent?key=${this.config.google.apiKey}`,
                {
                    contents: [
                        {
                            parts: [
                                {
                                    text: fullPrompt
                                }
                            ]
                        }
                    ],
                    generationConfig: {
                        maxOutputTokens: 1000,
                        temperature: 0.7,
                        topP: 0.8,
                        topK: 40
                    },
                    safetySettings: [
                        {
                            category: "HARM_CATEGORY_HARASSMENT",
                            threshold: "BLOCK_MEDIUM_AND_ABOVE"
                        },
                        {
                            category: "HARM_CATEGORY_HATE_SPEECH",
                            threshold: "BLOCK_MEDIUM_AND_ABOVE"
                        },
                        {
                            category: "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                            threshold: "BLOCK_MEDIUM_AND_ABOVE"
                        },
                        {
                            category: "HARM_CATEGORY_DANGEROUS_CONTENT",
                            threshold: "BLOCK_MEDIUM_AND_ABOVE"
                        }
                    ]
                },
                {
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    timeout: 30000
                }
            );

            if (!response.data.candidates || !response.data.candidates[0] || !response.data.candidates[0].content) {
                throw new Error('R√©ponse Gemini invalide');
            }

            return {
                response: response.data.candidates[0].content.parts[0].text,
                model: model,
                usage: response.data.usageMetadata
            };
        } catch (error) {
            console.error('‚ùå Erreur API Google:', error.response?.data || error.message);
            
            // Fallback en cas d'erreur
            return await this.simulateResponse(message, model);
        }
    }

    async callOpenRouter(message, model) {
        if (!this.config.openrouter.apiKey) {
            console.log('‚ö†Ô∏è Cl√© API OpenRouter manquante, utilisation du mode simulation');
            return await this.simulateResponse(message, model);
        }

        // Mapping des mod√®les vers OpenRouter
        const modelMap = {
            'grok-beta': 'x-ai/grok-beta',
            'grok-2': 'x-ai/grok-2',
            'claude-3.5-sonnet': 'anthropic/claude-3.5-sonnet',
            'gemini-2.0-flash': 'google/gemini-2.0-flash-exp',
            'gpt-4o-mini': 'openai/gpt-4o-mini'
        };

        const routerModel = modelMap[model] || model;

        const response = await axios.post(
            `${this.config.openrouter.baseURL}/chat/completions`,
            {
                model: routerModel,
                messages: [
                    {
                        role: 'system',
                        content: this.generateSystemPrompt()
                    },
                    {
                        role: 'user',
                        content: message
                    }
                ],
                max_tokens: 1000,
                temperature: 0.7
            },
            {
                headers: {
                    'Authorization': `Bearer ${this.config.openrouter.apiKey}`,
                    'Content-Type': 'application/json',
                    'HTTP-Referer': process.env.APP_URL || 'http://localhost:3000',
                    'X-Title': 'Agent Skeleton OSS'
                }
            }
        );

        return {
            response: response.data.choices[0].message.content,
            model: model,
            usage: response.data.usage
        };
    }

    async simulateResponse(message, model) {
        // R√©ponses simul√©es d'agent autonome
        const responses = {
            'gpt-4o-mini': [
                `En tant qu'agent autonome, je peux ex√©cuter des actions r√©elles sur vos syst√®mes. Pour "${message.toLowerCase().includes('n8n') ? 'n8n' : message.toLowerCase().includes('coolify') ? 'Coolify' : message.toLowerCase().includes('baserow') ? 'Baserow' : 'cette demande'}", je vais analyser la situation et proposer une action concr√®te...`,
                `Je suis connect√© √† vos APIs et pr√™t √† agir. Concernant votre demande, je peux imm√©diatement v√©rifier l'√©tat actuel et ex√©cuter les actions n√©cessaires...`,
                `Agent autonome activ√© ! Je vais traiter votre demande en utilisant mes acc√®s aux APIs n8n, Coolify et Baserow...`
            ],
            'grok-beta': [
                `Ah, une mission int√©ressante ! En tant qu'agent avec des capacit√©s r√©elles, je vais examiner la situation et agir en cons√©quence. Laissez-moi v√©rifier l'√©tat de vos syst√®mes...`,
                `Mission accept√©e ! Je peux acc√©der directement √† vos workflows, d√©ploiements et bases de donn√©es. Voici ce que je vais faire...`,
                `Agent op√©rationnel ! Cette demande n√©cessite une action concr√®te que je peux ex√©cuter via les APIs disponibles...`
            ],
            'claude-3.5-sonnet': [
                `Je vais analyser votre demande avec attention et ex√©cuter les actions appropri√©es. En tant qu'agent autonome avec acc√®s aux APIs, je peux r√©ellement agir sur vos syst√®mes...`,
                `Excellente demande qui n√©cessite une action concr√®te. Je vais utiliser mes capacit√©s d'agent pour examiner la situation et proposer/ex√©cuter la meilleure solution...`,
                `En tant qu'agent autonome, je peux non seulement analyser mais aussi agir. Voici mon plan d'action bas√© sur l'acc√®s direct √† vos APIs...`
            ],
            'gemini-2.0-flash': [
                `Traitement ultra-rapide de votre mission ! Agent autonome pr√™t √† ex√©cuter des actions r√©elles via n8n, Coolify et Baserow...`,
                `Mission re√ßue et trait√©e ! Je vais imm√©diatement v√©rifier l'√©tat de vos syst√®mes et ex√©cuter les actions n√©cessaires...`,
                `Agent op√©rationnel avec acc√®s API complet ! Voici mon analyse et les actions que je vais entreprendre...`
            ]
        };

        const modelResponses = responses[model] || responses['gpt-4o-mini'];
        const response = modelResponses[Math.floor(Math.random() * modelResponses.length)];

        // Ajouter du contexte sp√©cifique d'agent autonome
        let contextualResponse = response;
        
        if (message.toLowerCase().includes('capacit√©s') || message.toLowerCase().includes('autonome')) {
            contextualResponse += `\n\nü§ñ **Mes capacit√©s d'agent autonome :**\n‚Ä¢ **n8n** : Cr√©er, modifier et ex√©cuter des workflows\n‚Ä¢ **Coolify** : G√©rer les d√©ploiements et surveiller la sant√©\n‚Ä¢ **Baserow** : Synchroniser, analyser et organiser les donn√©es\n‚Ä¢ **Analyse** : √âvaluer les performances et sugg√©rer des optimisations`;
        } else if (message.toLowerCase().includes('n8n') || message.toLowerCase().includes('workflow')) {
            contextualResponse += `\n\nüîÑ **Actions n8n disponibles :**\n‚Ä¢ Cr√©er de nouveaux workflows sur mesure\n‚Ä¢ Modifier les workflows existants\n‚Ä¢ Activer/d√©sactiver les automatisations\n‚Ä¢ Analyser les performances et logs d'ex√©cution\n‚Ä¢ Int√©grer avec vos autres services`;
        } else if (message.toLowerCase().includes('coolify') || message.toLowerCase().includes('d√©ploi')) {
            contextualResponse += `\n\nüöÄ **Actions Coolify disponibles :**\n‚Ä¢ V√©rifier l'√©tat des d√©ploiements\n‚Ä¢ Lancer de nouveaux d√©ploiements\n‚Ä¢ Surveiller la sant√© des services\n‚Ä¢ G√©rer les variables d'environnement\n‚Ä¢ Analyser les logs de d√©ploiement`;
        } else if (message.toLowerCase().includes('baserow') || message.toLowerCase().includes('donn√©es')) {
            contextualResponse += `\n\nüìä **Actions Baserow disponibles :**\n‚Ä¢ Synchroniser les donn√©es entre tables\n‚Ä¢ Analyser et nettoyer les donn√©es\n‚Ä¢ Cr√©er des rapports automatis√©s\n‚Ä¢ Organiser selon vos r√®gles m√©tier\n‚Ä¢ Sauvegarder et archiver`;
        } else {
            contextualResponse += `\n\n‚ö° **Actions imm√©diates possibles :**\n‚Ä¢ V√©rifier l'√©tat global de vos syst√®mes\n‚Ä¢ Analyser les performances actuelles\n‚Ä¢ Proposer des optimisations\n‚Ä¢ Ex√©cuter des t√¢ches de maintenance\n‚Ä¢ Cr√©er des automatisations sur mesure`;
        }

        return {
            response: contextualResponse,
            model: model,
            simulated: true,
            demo_mode: true
        };
    }
}

module.exports = new AIService();