const express = require('express');
const axios = require('axios');
const path = require('path');
const helmet = require('helmet');
const cors = require('cors');
const rateLimit = require('express-rate-limit');
const { body, validationResult } = require('express-validator');

// Import du service IA
const aiService = require('./services/aiService');

const app = express();
const port = process.env.PORT || 3000;

// ğŸ”’ SÃ‰CURITÃ‰ : Configuration des headers de sÃ©curitÃ©
app.use(helmet({
    contentSecurityPolicy: {
        directives: {
            defaultSrc: ["'self'"],
            styleSrc: ["'self'", "'unsafe-inline'", "https://cdnjs.cloudflare.com", "https://fonts.googleapis.com"],
            scriptSrc: ["'self'", "'unsafe-inline'"],
            fontSrc: ["'self'", "https://cdnjs.cloudflare.com", "https://fonts.gstatic.com"],
            imgSrc: ["'self'", "data:", "https:"],
            connectSrc: ["'self'"]
        }
    },
    hsts: {
        maxAge: 31536000,
        includeSubDomains: true,
        preload: true
    }
}));

// Configuration du moteur de templates
app.set('view engine', 'ejs');
app.set('views', path.join(__dirname, '../views'));

// ğŸ”’ CORS Configuration
const allowedOrigins = process.env.ALLOWED_ORIGINS
    ? process.env.ALLOWED_ORIGINS.split(',')
    : ['http://localhost:3000'];

app.use(cors({
    origin: allowedOrigins,
    credentials: true,
    optionsSuccessStatus: 200
}));

// ğŸ”’ Rate Limiting
const limiter = rateLimit({
    windowMs: 15 * 60 * 1000, // 15 minutes
    max: 100, // limite chaque IP Ã  100 requÃªtes par windowMs
    message: {
        error: 'Trop de requÃªtes depuis cette IP, rÃ©essayez plus tard.',
        retryAfter: '15 minutes'
    },
    legacyHeaders: false
});

const chatLimiter = rateLimit({
    windowMs: 1 * 60 * 1000, // 1 minute
    max: 10, // limite chaque IP Ã  10 requÃªtes de chat par minute
    message: {
        error: 'Trop de messages de chat, attendez avant de continuer.',
        retryAfter: '1 minute'
    }
});

app.use(limiter);

// Middleware pour parsing JSON et URL-encoded
app.use(express.json());
app.use(express.urlencoded({ extended: true }));

// Fichiers statiques
app.use(express.static(path.join(__dirname, '../public')));

// ğŸ  Route principale - Interface moderne
app.get('/', (req, res) => {
    res.render('app', {
        title: 'Agent Skeleton OSS',
        version: '1.0.0'
    });
});

// ğŸ“± Route pour l'interface moderne
app.get('/app', (req, res) => {
    res.render('app', {
        title: 'Agent Skeleton OSS - Interface Moderne',
        version: '1.0.0'
    });
});

// ğŸ”§ Route de debug pour tester la navigation
app.get('/debug', (req, res) => {
    res.render('app_debug', {
        title: 'Agent Skeleton OSS - Debug Interface',
        version: '1.0.0'
    });
});

// ğŸ” Health Check
app.get('/health', (req, res) => {
    res.status(200).json({
        status: 'healthy',
        timestamp: new Date().toISOString(),
        version: '1.0.0',
        environment: process.env.NODE_ENV || 'development'
    });
});

// ğŸ”‘ API Keys Status Check (pour debug)
app.get('/api/keys-status', (req, res) => {
    const status = {
        openai: !!process.env.OPENAI_API_KEY,
        anthropic: !!process.env.ANTHROPIC_API_KEY,
        google: !!process.env.GOOGLE_API_KEY,
        openrouter: !!process.env.OPENROUTER_API_KEY,
        keys_count: [
            process.env.OPENAI_API_KEY,
            process.env.ANTHROPIC_API_KEY, 
            process.env.GOOGLE_API_KEY,
            process.env.OPENROUTER_API_KEY
        ].filter(Boolean).length,
        demo_mode: ![
            process.env.OPENAI_API_KEY,
            process.env.ANTHROPIC_API_KEY, 
            process.env.GOOGLE_API_KEY,
            process.env.OPENROUTER_API_KEY
        ].some(Boolean)
    };
    
    res.json(status);
});

// ğŸ’¬ API Chat avec validation et rate limiting
app.post('/api/chat', chatLimiter, async (req, res) => {
    try {
        console.log('ğŸ” DonnÃ©es reÃ§ues brutes:', req.body);
        
        const { message, conversationId, model } = req.body;
        
        // Validation simple manuelle
        if (!message || typeof message !== 'string' || message.trim().length === 0) {
            console.log('âŒ Message invalide:', message);
            return res.status(400).json({
                error: 'Message requis',
                details: 'Le message ne peut pas Ãªtre vide'
            });
        }

        console.log('âœ… Message valide reÃ§u:', { message, conversationId, model });
        
        // Debug des clÃ©s API
        console.log('ğŸ”‘ Ã‰tat des clÃ©s API:', {
            OPENAI: !!process.env.OPENAI_API_KEY,
            ANTHROPIC: !!process.env.ANTHROPIC_API_KEY,
            GOOGLE: !!process.env.GOOGLE_API_KEY,
            OPENROUTER: !!process.env.OPENROUTER_API_KEY
        });

        // Responses basÃ©es sur le modÃ¨le sÃ©lectionnÃ©
        const modelResponses = {
            'claude-3.5-sonnet': [
                "ğŸ§  Claude 3.5 Sonnet ici ! Je vais analyser votre demande avec attention.",
                "ğŸ” Excellente question ! Avec Claude, je peux vous aider Ã  explorer cette idÃ©e en profondeur.",
                "ğŸ’¡ En tant que Claude 3.5 Sonnet, je propose une approche mÃ©thodique pour rÃ©soudre cela.",
                "ğŸ“Š GrÃ¢ce aux capacitÃ©s de Claude, voici une analyse dÃ©taillÃ©e de votre demande.",
                "ğŸ¯ Claude 3.5 Sonnet est conÃ§u pour vous fournir des rÃ©ponses nuancÃ©es et pertinentes."
            ],
            'gpt-4': [
                "ï¿½ GPT-4 activÃ© ! Je vais traiter votre requÃªte avec ma comprÃ©hension avancÃ©e.",
                "âš¡ Excellent ! GPT-4 est parfait pour ce type de question complexe.",
                "ğŸ­ Avec GPT-4, je peux aborder votre demande sous plusieurs angles crÃ©atifs.",
                "ï¿½ Utilisant les capacitÃ©s de GPT-4, voici une rÃ©ponse structurÃ©e pour vous.",
                "ğŸŒŸ GPT-4 me permet de vous offrir une perspective riche et dÃ©taillÃ©e."
            ],
            'gemini-pro': [
                "ğŸ’ Gemini Pro en action ! Analysons cela ensemble de maniÃ¨re intelligente.",
                "ğŸŒˆ Avec Gemini Pro, j'apporte une approche multimodale Ã  votre question.",
                "ğŸ”® Gemini Pro me donne la flexibilitÃ© pour explorer votre demande crÃ©ativement.",
                "â­ GrÃ¢ce Ã  Gemini Pro, je peux connecter diffÃ©rents concepts pour vous aider.",
                "ï¿½ Gemini Pro excelle dans la comprÃ©hension nuancÃ©e de votre demande."
            ]
        };

        // RÃ©ponses gÃ©nÃ©riques pour les autres modÃ¨les
        const genericResponses = [
            `ğŸ¤– ${model || 'IA'} : Votre message est bien reÃ§u ! Comment puis-je vous aider davantage ?`,
            `ğŸ’­ Avec ${model || 'ce modÃ¨le'}, je traite votre demande avec soin.`,
            `ğŸ”§ ${model || 'Le systÃ¨me'} analyse votre question et prÃ©pare une rÃ©ponse adaptÃ©e.`,
            `ğŸ“ Utilisant ${model || 'les capacitÃ©s IA'}, voici ma rÃ©flexion sur votre demande.`,
            `ğŸ¯ ${model || 'L\'assistant'} est prÃªt Ã  vous accompagner dans cette tÃ¢che.`
        ];

        // Appel du service IA rÃ©el
        const aiResponse = await aiService.sendMessage(message, model, conversationId);
        
        console.log('ğŸ¤– RÃ©ponse IA reÃ§ue:', aiResponse);

        // Si c'est une simulation, on ajoute un indicateur
        let finalResponse = aiResponse.response;
        if (aiResponse.simulated) {
            finalResponse = `${aiResponse.response}\n\nğŸ’¡ *Mode dÃ©mo - Configurez vos clÃ©s API pour activer l'IA complÃ¨te*`;
        } else if (aiResponse.error) {
            finalResponse = aiResponse.response;
        }

        res.json({
            response: finalResponse,
            conversationId: conversationId || `conv_${Date.now()}`,
            timestamp: new Date().toISOString(),
            model: model || 'assistant',
            usage: aiResponse.usage || null,
            simulated: aiResponse.simulated || false
        });

    } catch (error) {
        console.error('Erreur API Chat:', error);
        res.status(500).json({
            error: 'Erreur interne du serveur',
            message: 'Une erreur est survenue lors du traitement de votre message'
        });
    }
});

// ğŸ“ API Instructions personnalisÃ©es
app.get('/api/instructions', (req, res) => {
    res.json({
        instructions: aiService.customInstructions
    });
});

app.post('/api/instructions', [
    body('brand').optional().isString().trim(),
    body('tone').optional().isString().trim(),
    body('expertise').optional().isString().trim(),
    body('language').optional().isString().trim(),
    body('personality').optional().isString().trim()
], (req, res) => {
    try {
        const errors = validationResult(req);
        if (!errors.isEmpty()) {
            return res.status(400).json({
                error: 'DonnÃ©es invalides',
                details: errors.array()
            });
        }

        // Filtrer les champs non-null
        const newInstructions = {};
        ['brand', 'tone', 'expertise', 'language', 'personality'].forEach(field => {
            if (req.body[field] !== undefined && req.body[field] !== '') {
                newInstructions[field] = req.body[field];
            }
        });

        // Mettre Ã  jour les instructions
        aiService.updateInstructions(newInstructions);

        res.json({
            success: true,
            instructions: aiService.customInstructions,
            message: 'Instructions mises Ã  jour avec succÃ¨s'
        });

    } catch (error) {
        console.error('Erreur API Instructions:', error);
        res.status(500).json({
            error: 'Erreur interne du serveur',
            message: 'Une erreur est survenue lors de la mise Ã  jour'
        });
    }
});

// ğŸ“Š API Status
app.get('/api/status', (req, res) => {
    res.json({
        status: 'online',
        version: '1.0.0',
        timestamp: new Date().toISOString(),
        uptime: process.uptime(),
        memory: process.memoryUsage(),
        environment: process.env.NODE_ENV || 'development'
    });
});

// ğŸ”§ Middleware de gestion d'erreurs
app.use((err, req, res, next) => {
    console.error('Erreur:', err);
    res.status(500).json({
        error: 'Erreur interne du serveur',
        message: process.env.NODE_ENV === 'development' ? err.message : 'Une erreur est survenue'
    });
});

// 404 Handler
app.use((req, res) => {
    res.status(404).json({
        error: 'Page non trouvÃ©e',
        message: `La route ${req.originalUrl} n'existe pas`
    });
});

// DÃ©marrage du serveur
app.listen(port, () => {
    console.log(`ğŸš€ Agent Skeleton OSS dÃ©marrÃ© sur le port ${port}`);
    console.log(`ğŸŒ Interface disponible : http://localhost:${port}/app`);
    console.log(`ğŸ’š Health check : http://localhost:${port}/health`);
    console.log(`ğŸ“¡ API Status : http://localhost:${port}/api/status`);
});

module.exports = app;